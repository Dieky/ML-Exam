{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6827345",
   "metadata": {},
   "source": [
    "# K-Means Clustering Analysis of Airbnb Data\n",
    "\n",
    "This notebook performs K-means clustering analysis on Airbnb listing data to identify distinct groups of listings with similar characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f72fa",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "First, we import the necessary libraries for data manipulation, clustering, visualization and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c391485-1867-4293-a6ee-e3e27aad7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb6c2e",
   "metadata": {},
   "source": [
    "Load the cleaned Airbnb dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101c73cd-3b9a-4d72-982f-3e7b64c2fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../ML-Exam/data/cleaned_airbnb_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f7c70",
   "metadata": {},
   "source": [
    "## Finding Optimal Number of Clusters\n",
    "\n",
    "We use the elbow method to determine the optimal number of clusters. This involves:\n",
    "1. Selecting and standardizing numerical features\n",
    "2. Running K-means with different k values\n",
    "3. Calculating the inertia (within-cluster sum of squares)\n",
    "4. Finding the 'elbow point' where adding more clusters gives diminishing returns\n",
    "\n",
    "We also calculate the percentage improvement between successive k values to make the decision more objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c3289-bdf0-43dc-8b43-1a6c4f82783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for clustering\n",
    "numerical_features = ['realSum', 'person_capacity', 'cleanliness_rating', \n",
    "                      'guest_satisfaction_overall', 'bedrooms', 'dist', 'metro_dist',\n",
    "                      'host_is_superhost_bool', 'Is_weekend_bool','room_private_bool']\n",
    "\n",
    "# Create a copy of the data with just numerical features\n",
    "cluster_data = df[numerical_features].copy()\n",
    "\n",
    "# Standardize the data for clustering\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(cluster_data)\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(scaled_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Find the elbow point using the rate of change\n",
    "inertia_array = np.array(inertia)\n",
    "# Calculate percentage of change in inertia\n",
    "inertia_diffs = np.diff(inertia_array) / inertia_array[:-1] * 100\n",
    "# Convert to absolute values (since changes are negative)\n",
    "inertia_diffs_abs = np.abs(inertia_diffs)\n",
    "\n",
    "# Find the last k value where improvement is above the threshold\n",
    "threshold = 10  # percentage improvement threshold\n",
    "optimal_k = 2  # default to 2 if no clear elbow\n",
    "\n",
    "# Identify the last k value where the improvement is above threshold\n",
    "last_above_threshold = None\n",
    "for i, diff_pct in enumerate(inertia_diffs_abs):\n",
    "    k_value = i + 2  # k value is i+2 (since we're looking at differences and k starts at 1)\n",
    "    if diff_pct >= threshold:\n",
    "        last_above_threshold = k_value\n",
    "\n",
    "# Set optimal_k to be the last k with improvement above threshold\n",
    "if last_above_threshold is not None:\n",
    "    optimal_k = last_above_threshold  # Use exactly the last k above threshold\n",
    "\n",
    "# Print the actual improvement percentages for clarity\n",
    "print(\"Improvement percentages for each additional cluster:\")\n",
    "for i, pct in enumerate(inertia_diffs_abs):\n",
    "    k_val = i + 2  # k starts at 2 for diffs\n",
    "    print(f\"  k={k_val}: {pct:.2f}% improvement\")\n",
    "    if k_val == last_above_threshold:\n",
    "        print(f\"  --> Last value above {threshold}% threshold\")\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Main plot - inertia\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(k_range, inertia, marker='o', linewidth=2)\n",
    "plt.axvline(x=optimal_k, color='r', linestyle='--', label=f'Optimal k = {optimal_k}')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Secondary plot - percentage improvement\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(2, len(k_range) + 1), inertia_diffs_abs, alpha=0.7)\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold = {threshold}%')\n",
    "# Mark the optimal k\n",
    "plt.axvline(x=optimal_k, color='green', linestyle='--', \n",
    "           label=f'Optimal k = {optimal_k}')\n",
    "plt.title('Percentage Improvement with Additional Cluster')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Improvement (%)')\n",
    "plt.xticks(range(2, len(k_range) + 1))\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Automatically determined optimal k = {optimal_k} (last cluster with improvement >= {threshold}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaaf38a",
   "metadata": {},
   "source": [
    "## Performing K-Means Clustering\n",
    "\n",
    "Based on the elbow analysis, we choose k=5 clusters and fit the K-means model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7394a2-b028-4179-b13f-9d986ec5cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 5  # Update this based on your elbow plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1a541",
   "metadata": {},
   "source": [
    "## Analyzing Cluster Distribution by City\n",
    "\n",
    "Visualize how the clusters are distributed across different cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a52fe-567c-4b03-8433-fe8689db29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='City', hue='cluster')\n",
    "plt.title(\"Listings by City and Cluster\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6490df7",
   "metadata": {},
   "source": [
    "## Examining Cluster Characteristics\n",
    "\n",
    "Calculate and display summary statistics for each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c513a-0574-40bd-a03e-fc182cd590b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary = df.groupby('cluster')[numerical_features].mean()\n",
    "cluster_summary\n",
    "df['cluster'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f3c0a",
   "metadata": {},
   "source": [
    "## Detailed Cluster Analysis\n",
    "\n",
    "Create a comprehensive visualization of cluster characteristics using:\n",
    "1. A styled table showing cluster centers\n",
    "2. A radar chart comparing different aspects of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the clusters\n",
    "# Get the cluster centers and transform back to original scale\n",
    "centers = kmeans.cluster_centers_\n",
    "centers_original = scaler.inverse_transform(centers)\n",
    "\n",
    "# Create a DataFrame with the cluster centers\n",
    "centers_df = pd.DataFrame(centers_original, columns=numerical_features)\n",
    "centers_df.index = [f'Cluster {i}' for i in range(optimal_k)]\n",
    "\n",
    "# Display the cluster centers using a clean styled table with alternating row colors\n",
    "centers_df_styled = centers_df.round(2).style.set_caption(\"Cluster Centers (Original Scale)\")\\\n",
    "    .set_properties(**{\n",
    "        'text-align': 'center',\n",
    "        'color': 'black',\n",
    "    })\\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('font-weight', 'bold'), ('font-size', '16px')]},\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('text-align', 'center'), \n",
    "            ('background-color', '#d9d9d9'),\n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold')\n",
    "        ]},\n",
    "        {'selector': 'tbody tr:nth-child(even)', 'props': [('background-color', '#f2f2f2')]},\n",
    "        {'selector': 'tbody tr:nth-child(odd)', 'props': [('background-color', 'white')]},\n",
    "    ])\n",
    "\n",
    "display(centers_df_styled)\n",
    "\n",
    "# Visualize cluster characteristics with a radar chart\n",
    "def radar_chart(df, title, colors=None):\n",
    "    # Define feature groups\n",
    "    feature_groups = {\n",
    "        'Location': ['dist', 'metro_dist'],\n",
    "        'Accommodation': ['bedrooms', 'person_capacity'],\n",
    "        'Quality': ['cleanliness_rating', 'guest_satisfaction_overall'],\n",
    "        'Price': ['realSum'],\n",
    "        'Superhost': ['host_is_superhost_bool']\n",
    "    }\n",
    "    \n",
    "    # Create a new DataFrame to store group averages\n",
    "    group_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Calculate the average for each feature group\n",
    "    for group_name, features in feature_groups.items():\n",
    "        valid_features = [f for f in features if f in df.columns]\n",
    "        if valid_features:\n",
    "            group_df[group_name] = df[valid_features].mean(axis=1)\n",
    "    \n",
    "    categories = list(group_df.columns)\n",
    "    N = len(categories)\n",
    "    \n",
    "    # Normalize the data for the radar chart\n",
    "    normalized_df = pd.DataFrame(index=group_df.index, columns=group_df.columns)\n",
    "    \n",
    "    for col in group_df.columns:\n",
    "        feature_values = group_df[col].values\n",
    "        normalized_values = stats.zscore(feature_values)\n",
    "        normalized_df[col] = normalized_values\n",
    "    \n",
    "    # Scale to [0,1] range\n",
    "    min_val = normalized_df.values.min()\n",
    "    max_val = normalized_df.values.max()\n",
    "    \n",
    "    for col in normalized_df.columns:\n",
    "        normalized_df[col] = (normalized_df[col] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    print(\"Z-score normalized cluster means by feature group (scaled to [0,1] for visualization):\")\n",
    "    \n",
    "    # Style the normalized values table\n",
    "    norm_df_styled = normalized_df.round(2).style\\\n",
    "        .background_gradient(cmap='Blues')\\\n",
    "        .set_properties(**{\n",
    "            'text-align': 'center',\n",
    "            'font-weight': 'bold'\n",
    "        })\\\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', 'props': [\n",
    "                ('text-align', 'center'), \n",
    "                ('background-color', '#d9d9d9'),\n",
    "                ('color', 'black'),\n",
    "                ('font-weight', 'bold')\n",
    "            ]},\n",
    "        ])\n",
    "    \n",
    "    display(norm_df_styled)\n",
    "    \n",
    "    # Create the radar chart\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(group_df.index)))\n",
    "    \n",
    "    for i, cluster in enumerate(group_df.index):\n",
    "        values = normalized_df.loc[cluster, categories].values.flatten().tolist()\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, linewidth=2, label=cluster, color=colors[i])\n",
    "        ax.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "    \n",
    "    plt.xticks(angles[:-1], categories, size=12)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1), fontsize=12)\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.25, 0.5, 0.75], [\"0.25\", \"0.5\", \"0.75\"], color=\"grey\", size=10)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.title(title, size=20, y=1.1)\n",
    "    return fig, ax\n",
    "\n",
    "# Create the radar chart\n",
    "radar_chart(centers_df, \"Cluster Characteristics: Location, Accommodation, Quality, Price, Superhost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319254f9",
   "metadata": {},
   "source": [
    "## Visualizing Clusters in 2D\n",
    "\n",
    "Use PCA to reduce the dimensionality of our data to 2D for visualization. This helps us see how well-separated the clusters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7403cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create a dataframe with PCA results and cluster labels\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['cluster'] = df['cluster']\n",
    "pca_df['price'] = df['realSum']\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='cluster',\n",
    "    size='price',\n",
    "    sizes=(20, 200),\n",
    "    palette='viridis',\n",
    "    data=pca_df,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add centers to the plot\n",
    "centers = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=1, marker='X', edgecolor='black')\n",
    "\n",
    "plt.title(f'K-Means Clustering of Airbnb Listings (PCA-Reduced, k={optimal_k})')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb526f3f",
   "metadata": {},
   "source": [
    "## Save Clustered Data\n",
    "\n",
    "Save the data with cluster assignments for future use, removing any old cluster columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d620c47-cc65-40d0-8c70-577cc7e4ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['cluster_4', 'cluster_6'], errors='ignore')  # `errors='ignore'` makes it safe if they don't exist\n",
    "df.to_csv(\"../ML-exam/data/clustered_airbnb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
