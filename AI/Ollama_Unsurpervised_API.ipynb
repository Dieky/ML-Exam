{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustered Airbnb data from the user's GitHub project path\n",
    "df = pd.read_csv(\"../data/clustered_airbnb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### LLaMA 3 Client  \n",
    "This class provides a simple interface for interacting with a locally running LLaMA 3 model via Ollama's HTTP API. It sends structured prompts to the model and retrieves natural-language responses to assist in Airbnb listing recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama3Client:\n",
    "    def __init__(self, model=\"llama3\", host=\"http://localhost:11434\"):\n",
    "        # Set the model name and API host address\n",
    "        self.model = model\n",
    "        self.api_url = f\"{host}/api/chat\"\n",
    "\n",
    "    def ask(self, prompt: str) -> str:\n",
    "        # Create the request payload for Ollama's chat endpoint\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"stream\": False  # Disable streaming for full response in one block\n",
    "        }\n",
    "        try:\n",
    "            # Send POST request to local Ollama server\n",
    "            response = requests.post(self.api_url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            # Extract and return the assistant's message content\n",
    "            return response.json()['message']['content'].strip()\n",
    "        except requests.RequestException as e:\n",
    "            # Return error if something went wrong\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Format Listings for Prompt  \n",
    "This function converts a filtered DataFrame of Airbnb listings into a readable, structured text block. The formatted output is embedded into the LLM prompt to help the model understand and compare the listings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_listings(listings_df, nights):\n",
    "    listings = []\n",
    "\n",
    "    for _, row in listings_df.iterrows():\n",
    "        # Calculate total cost for the user's stay\n",
    "        total_price = row['realSum'] * nights\n",
    "\n",
    "        # Create a string representation of the listing\n",
    "        listing = (\n",
    "            f\"{row['City']} (Cluster {row['cluster']}) - €{row['realSum']}/night, \"\n",
    "            f\"{row['bedrooms']} bedrooms, \"\n",
    "            f\"{row['dist']}km to center, \"\n",
    "            f\"{row['metro_dist']}km to metro, \"\n",
    "            f\"{row['guest_satisfaction_overall']} guest satisfaction, \"\n",
    "            f\"Total: €{total_price:.2f}, \"\n",
    "            f\"Value Score: {row['value_score']:.1f}\"\n",
    "        )\n",
    "\n",
    "        listings.append(listing)\n",
    "\n",
    "    # Combine all listings into a single multi-line string\n",
    "    return \"\\n\".join(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Semantic Retriever  \n",
    "This function uses TF-IDF vectorization and cosine similarity to create a simple semantic search engine. It identifies the listings that best match the user's natural language query by ranking them based on textual similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_listings(df, user_query, top_k=5):\n",
    "    # Copy the original DataFrame to avoid modifying it directly\n",
    "    df = df.copy()\n",
    "\n",
    "    # Combine listing features into a single text blob for semantic search\n",
    "    df['search_blob'] = df.apply(\n",
    "        lambda row: f\"{row['City']} {row['room_type']} {row['bedrooms']} bedrooms \"\n",
    "                    f\"{row['dist']}km from center {row['metro_dist']}km from metro \"\n",
    "                    f\"€{row['realSum']}/night {row['guest_satisfaction_overall']} rating\", axis=1\n",
    "    )\n",
    "\n",
    "    # Transform all listings into TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['search_blob'])\n",
    "\n",
    "    # Transform the user's query into a TF-IDF vector\n",
    "    query_vector = vectorizer.transform([user_query])\n",
    "\n",
    "    # Compute cosine similarity between the query and all listings\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort by similarity and return the top-k matches\n",
    "    top_indices = similarities.argsort()[::-1][:top_k]\n",
    "    return df.iloc[top_indices].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Value Score Calculation Function  \n",
    "This function calculates a `value_score` for each Airbnb listing by combining key features such as price, proximity to the city center and metro, number of bedrooms, and guest satisfaction. The scores are normalized on a 0–100 scale, allowing the listings to be ranked by overall value for money.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_value_scores(df):\n",
    "    # Work on a copy to avoid modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Invert features where lower values are better ---\n",
    "    # Inverse price: cheaper is better\n",
    "    df['inv_price'] = 1 / df['realSum']\n",
    "    \n",
    "    # Inverse distances (add 0.1 to avoid division by zero)\n",
    "    df['inv_dist'] = 1 / (df['dist'] + 0.1)\n",
    "    df['inv_metro'] = 1 / (df['metro_dist'] + 0.1)\n",
    "\n",
    "    # --- Combine selected features into a scoring matrix ---\n",
    "    # We use both direct (bedrooms, satisfaction) and inverse (price, distance) metrics\n",
    "    scoring_data = pd.DataFrame({\n",
    "        'price': df['inv_price'],                           # Favor cheaper listings\n",
    "        'center': df['inv_dist'],                           # Favor closer to city center\n",
    "        'metro': df['inv_metro'],                           # Favor closer to metro\n",
    "        'bedrooms': df['bedrooms'],                         # Favor more rooms\n",
    "        'satisfaction': df['guest_satisfaction_overall']    # Favor higher guest scores\n",
    "    })\n",
    "    \n",
    "    # --- Normalize features using Min-Max scaling ---\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized = scaler.fit_transform(scoring_data)\n",
    "\n",
    "    # Average the normalized features to get a raw value score\n",
    "    raw_score = normalized.mean(axis=1)\n",
    "\n",
    "    # --- Final Value Score Scaling (0–100) ---\n",
    "    max_score = raw_score.max()\n",
    "    if pd.notna(max_score) and max_score != 0:\n",
    "        df['value_score'] = (raw_score / max_score) * 100\n",
    "    else:\n",
    "        # Handle edge case: no variability or invalid score\n",
    "        df['value_score'] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Recommended Best Listing Function\n",
    "This function combines semantic search and value-based scoring to recommend the best Airbnb listing within a specific city, based on user preferences and budget. It uses a RAG (Retrieval-Augmented Generation) approach where filtered listings are passed to a local LLaMA 3 model for reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recommend Best Value (All Cities) using RAG-Powered Recommendation ---\n",
    "def recommend_best_listing(df, user_query, budget, nights=5, top_k=5):\n",
    "    # Step 1: Retrieve top-k semantically similar listings using the user's natural language query\n",
    "    retrieved = retrieve_similar_listings(df, user_query, top_k=top_k)\n",
    "\n",
    "    # Step 2: Add total price column (price per night * number of nights)\n",
    "    retrieved['total_price'] = retrieved['realSum'] * nights\n",
    "\n",
    "    # Step 3: Filter listings to include only those within the user's budget\n",
    "    filtered = retrieved[retrieved['total_price'] <= budget]\n",
    "\n",
    "    # Step 4: Return early if no listings match the criteria\n",
    "    if filtered.empty:\n",
    "        return \"No listings found within your budget and preferences.\"\n",
    "\n",
    "    # Step 5: Compute a custom value score based on price, distance, satisfaction, etc.\n",
    "    filtered = calculate_value_scores(filtered)\n",
    "\n",
    "    # Step 6: Format the filtered listings into text to be used in the LLM prompt\n",
    "    context = format_listings(filtered, nights)\n",
    "\n",
    "    # Step 7: Create a prompt that provides the listings and instructs the LLM to choose the best one\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, analytical travel assistant using semantic matching and listing data.\n",
    "\n",
    "The user is looking for:\n",
    "\"{user_query}\"\n",
    "\n",
    "Their budget is €{budget} for {nights} nights.\n",
    "\n",
    "Based on a semantic search, here are the top matching listings:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pick the best match and explain your reasoning clearly and logically.\n",
    "\n",
    "Respond in the following format:\n",
    "\n",
    "<City> (Cluster <#>) - €<price>/night, <#> bedrooms, <x>km to center, <y>km to metro, <guest satisfaction>, Total: €<total>, Value Score: <score>\n",
    "\n",
    "Here's why:\n",
    "* Total price: ...\n",
    "* Distance: ...\n",
    "* Bedrooms: ...\n",
    "* Satisfaction: ...\n",
    "* Final recommendation: ...\n",
    "\"\"\"\n",
    "\n",
    "    # Step 8: Use the local LLaMA 3 model to generate a recommendation based on the prompt\n",
    "    client = Llama3Client()\n",
    "    return client.ask(prompt)\n",
    "\n",
    "# --- Example Usage ---\n",
    "user_query = \"A quiet place near city center with good metro access and high ratings\"\n",
    "budget = 500\n",
    "nights = 5\n",
    "top_k = 10\n",
    "\n",
    "# Generate and display recommendation using LLaMA 3\n",
    "response = recommend_best_listing(df, user_query, budget, nights, top_k)\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Recommend Best Listing in City Function\n",
    "This function performs city-specific semantic retrieval and value-based scoring to recommend the best Airbnb listing that fits a user's preferences and budget. It applies a RAG (Retrieval-Augmented Generation) approach by passing the top filtered listings from a selected city into a locally hosted LLaMA 3 model for natural language reasoning and explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recommend Best Listing in a Specific City using RAG-Powered Recommendation ---\n",
    "def recommend_best_listing_in_city(df, city, user_query, budget, nights=5, top_k=5):\n",
    "    # Step 1: Filter dataset by the specified city (case-insensitive)\n",
    "    city_df = df[df['City'].str.lower() == city.lower()]\n",
    "    if city_df.empty:\n",
    "        return f\"No listings found in {city.title()}.\"\n",
    "\n",
    "    # Step 2: Perform semantic search on listings in this city using the user query\n",
    "    # This uses TF-IDF to find listings that are textually similar to the query\n",
    "    retrieved = retrieve_similar_listings(city_df, user_query, top_k=top_k)\n",
    "\n",
    "    # Step 3: Compute total price for the given stay length and filter by budget\n",
    "    retrieved['total_price'] = retrieved['realSum'] * nights\n",
    "    filtered = retrieved[retrieved['total_price'] <= budget]\n",
    "\n",
    "    if filtered.empty:\n",
    "        return f\"No listings found in {city.title()} matching your budget and preferences.\"\n",
    "\n",
    "    # Step 4: Calculate a value score based on price, satisfaction, proximity, and other features\n",
    "    filtered = calculate_value_scores(filtered)\n",
    "\n",
    "    # Step 5: Format the filtered results into human-readable listing descriptions for the prompt\n",
    "    context = format_listings(filtered, nights)\n",
    "\n",
    "    # Step 6: Build the prompt to send to the LLaMA 3 model\n",
    "    # This prompt contains user preferences, listings, and a specific output format\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, analytical travel assistant using semantic matching and listing data.\n",
    "\n",
    "The user is looking for:\n",
    "\"{user_query}\"\n",
    "\n",
    "Their budget is €{budget} for {nights} nights, and they want to stay in {city.title()}.\n",
    "\n",
    "Based on a semantic search within listings from this city, here are the top matches:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pick the best match and explain your reasoning clearly and logically.\n",
    "\n",
    "Respond in the following format:\n",
    "\n",
    "<City> (Cluster <#>) - €<price>/night, <#> bedrooms, <x>km to center, <y>km to metro, <guest satisfaction>, Total: €<total>, Value Score: <score>\n",
    "\n",
    "Here's why:\n",
    "* Total price: ...\n",
    "* Distance: ...\n",
    "* Bedrooms: ...\n",
    "* Satisfaction: ...\n",
    "* Final recommendation: ...\n",
    "\"\"\"\n",
    "\n",
    "    # Step 7: Send the prompt to the local LLaMA 3 model and return its answer\n",
    "    client = Llama3Client()\n",
    "    return client.ask(prompt)\n",
    "\n",
    "# --- Example Usage ---\n",
    "response = recommend_best_listing_in_city(\n",
    "    df,\n",
    "    city=\"Berlin\",\n",
    "    user_query=\"quiet place near city center with good metro access and high ratings\",\n",
    "    budget=1000,\n",
    "    nights=5,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "# Display the AI-generated recommendation in Markdown format\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Recommend Best Value Function (All Cities)\n",
    "This function identifies the best overall Airbnb listing across all available cities by filtering based on user budget, computing value scores from multiple features (price, distance, satisfaction, etc.), and formatting the listings into a structured prompt. It sends this prompt to a locally hosted LLaMA 3 model, which returns a natural-language recommendation based on the top-ranked options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recommend Best Value (All Cities) using to_string() Recommendation ---\n",
    "def recommend_best_value(df, budget, nights=5, max_results=5):\n",
    "    # Step 1: Calculate total cost for the user's stay\n",
    "    df['total_price'] = df['realSum'] * nights\n",
    "\n",
    "    # Step 2: Filter listings to only include those within the user's budget\n",
    "    filtered = df[df['total_price'] <= budget]\n",
    "\n",
    "    # Step 3: Sort listings by guest satisfaction and limit to top N results\n",
    "    filtered = filtered.sort_values(by='guest_satisfaction_overall', ascending=False).head(max_results)\n",
    "\n",
    "    # Step 4: If no listings are found after filtering, return a message\n",
    "    if filtered.empty:\n",
    "        return \"No listings found within your budget.\"\n",
    "\n",
    "    # Step 5: Calculate value scores for each listing using multiple features\n",
    "    filtered = calculate_value_scores(filtered)\n",
    "\n",
    "    # Step 6: Convert the filtered DataFrame to a plain-text table (no index)\n",
    "    context = filtered.to_string(index=False)\n",
    "\n",
    "    # Step 7: Construct a prompt to instruct the LLaMA 3 model to choose the best option\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, analytical travel assistant that uses logic and data to help users choose the best Airbnb listing.\n",
    "\n",
    "Your task is to evaluate the Airbnb listings shown below and select the single best option for the user's travel needs.\n",
    "\n",
    "The user has a total budget of €{budget} for {nights} nights. Below are the top Airbnb listings, already ranked by a calculated value score (out of 100):\n",
    "\n",
    "{context}\n",
    "\n",
    "Please consider the following criteria for your recommendation:\n",
    "- Total price (should stay within budget)\n",
    "- Distance to city center and metro\n",
    "- Number of bedrooms\n",
    "- Guest satisfaction score\n",
    "- Cluster number\n",
    "\n",
    "Return your response in the following format:\n",
    "\n",
    "After analyzing the available listings, I would recommend the following option:\n",
    "\n",
    "<Airbnb ID>, <City> (Cluster <#>) - €<price>/night, <#> bedrooms, <x>km to center, <y>km to metro, <guest satisfaction> guest satisfaction, Total: €<total price>, Value Score: <score>\n",
    "\n",
    "Here's why:\n",
    "* Value score: ...\n",
    "* Total price: ...\n",
    "* Distance to city center and metro: ...\n",
    "* Number of bedrooms: ...\n",
    "* Guest satisfaction: ...\n",
    "* Cluster (if relevant): ...\n",
    "\n",
    "Conclude with a confident recommendation summarizing why this is your top pick.\n",
    "\"\"\"\n",
    "\n",
    "    # Step 8: Query the local LLaMA 3 model with the structured prompt\n",
    "    client = Llama3Client()\n",
    "    return client.ask(prompt)\n",
    "\n",
    "# --- Example Usage ---\n",
    "budget = 500\n",
    "nights = 5\n",
    "\n",
    "# Generate and display the recommendation\n",
    "response_1 = recommend_best_value(df, budget=budget, nights=nights)\n",
    "display(Markdown(response_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Recommend Best Listing in a Specific City Function\n",
    "This function filters Airbnb listings by a specified city and budget, ranks them by guest satisfaction, calculates a composite value score, and sends the formatted top listings to a local LLaMA 3 model. The model then provides a personalized recommendation with reasoning based on multiple features like price, location, and guest satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recommend Best Listing Within a Specific City using to_string() Recommendation ---\n",
    "def recommend_in_city(df, city, budget, nights=5, max_results=5):\n",
    "    # Step 1: Calculate total price for each listing based on the length of stay\n",
    "    df['total_price'] = df['realSum'] * nights\n",
    "\n",
    "    # Step 2: Filter listings by city (case-insensitive) and budget\n",
    "    filtered = df[\n",
    "        (df['City'].str.lower() == city.lower()) &\n",
    "        (df['total_price'] <= budget)\n",
    "    ]\n",
    "\n",
    "    # Step 3: Sort listings by guest satisfaction and limit to the top results\n",
    "    filtered = filtered.sort_values(by='guest_satisfaction_overall', ascending=False).head(max_results)\n",
    "\n",
    "    # Step 4: Handle case where no listings are found\n",
    "    if filtered.empty:\n",
    "        return f\"No listings found in {city.title()} within your budget.\"\n",
    "\n",
    "    # Step 5: Compute value scores using normalized metrics (price, distance, satisfaction, etc.)\n",
    "    filtered = calculate_value_scores(filtered)\n",
    "\n",
    "    # Step 6: Convert the DataFrame to a text table for use in the LLM prompt\n",
    "    context = filtered.to_string(index=False)\n",
    "\n",
    "    # Step 7: Compose the LLM prompt with clear structure and evaluation criteria\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful, analytical travel assistant using semantic matching and listing data.\n",
    "\n",
    "The user is looking for:\n",
    "\"{user_query}\"\n",
    "\n",
    "Their budget is €{budget} for {nights} nights, and they want to stay in {city.title()}.\n",
    "\n",
    "Based on a semantic search within listings from this city, here are the top matches:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pick the best match and explain your reasoning clearly and logically.\n",
    "\n",
    "Respond in the following format:\n",
    "\n",
    "<City> (Cluster <#>) - €<price>/night, <#> bedrooms, <x>km to center, <y>km to metro, <guest satisfaction> guest satisfaction, Total: €<total>, Value Score: <score>\n",
    "\n",
    "Here's why:\n",
    "* Total price: ...\n",
    "* Distance: ...\n",
    "* Bedrooms: ...\n",
    "* Satisfaction: ...\n",
    "* Final recommendation: ...\n",
    "\"\"\"\n",
    "\n",
    "    # Step 8: Query the local LLaMA 3 model with the structured prompt\n",
    "    client = Llama3Client()\n",
    "    return client.ask(prompt)\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Set user parameters\n",
    "city = \"Barcelona\"\n",
    "budget = 500\n",
    "nights = 5\n",
    "\n",
    "# Call the function to get the LLM's recommendation\n",
    "response = recommend_in_city(df, city=city, budget=budget, nights=nights)\n",
    "\n",
    "# Display the AI-generated recommendation using markdown formatting\n",
    "display(Markdown(\"### Recommendation in City\"))\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Cluster Document Creation\n",
    "Creates detailed text descriptions for each cluster by calculating key statistics like average prices, satisfaction scores, and locations. This helps us understand and compare the different property groups.\n",
    "\n",
    "The clusters were created using K-means clustering on the property features. Each cluster represents a group of similar properties based on their characteristics like price, location, size, and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to analyze clusters\n",
    "def create_cluster_documents(df):\n",
    "    \"\"\"Create text documents describing each cluster's characteristics.\"\"\"\n",
    "    cluster_docs = []\n",
    "    cluster_ids = []\n",
    "    \n",
    "    # Get all unique clusters\n",
    "    clusters = sorted(df['cluster'].unique())\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        cluster_data = df[df['cluster'] == cluster]\n",
    "        \n",
    "        # Calculate statistics for this cluster\n",
    "        avg_price = cluster_data['realSum'].mean()\n",
    "        avg_satisfaction = cluster_data['guest_satisfaction_overall'].mean()\n",
    "        avg_dist = cluster_data['dist'].mean()\n",
    "        avg_metro_dist = cluster_data['metro_dist'].mean()\n",
    "        avg_bedrooms = cluster_data['bedrooms'].mean()\n",
    "        \n",
    "        # Room type distribution\n",
    "        room_types = cluster_data['room_type'].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        # City distribution\n",
    "        city_dist = cluster_data['City'].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        # Create a document describing this cluster\n",
    "        doc = f\"Cluster {cluster} characteristics:\\n\"\n",
    "        doc += f\"Average price: €{avg_price:.2f} per night\\n\"\n",
    "        doc += f\"Average guest satisfaction: {avg_satisfaction:.2f}/100\\n\"\n",
    "        doc += f\"Average distance to city center: {avg_dist:.2f}km\\n\"\n",
    "        doc += f\"Average distance to metro: {avg_metro_dist:.2f}km\\n\"\n",
    "        doc += f\"Average number of bedrooms: {avg_bedrooms:.2f}\\n\"\n",
    "        \n",
    "        doc += \"Room type distribution:\\n\"\n",
    "        for room_type, percentage in room_types.items():\n",
    "            doc += f\"- {room_type}: {percentage*100:.1f}%\\n\"\n",
    "            \n",
    "        doc += \"City distribution:\\n\"\n",
    "        for city, percentage in city_dist.items():\n",
    "            doc += f\"- {city}: {percentage*100:.1f}%\\n\"\n",
    "        \n",
    "        cluster_docs.append(doc)\n",
    "        cluster_ids.append(cluster)\n",
    "        \n",
    "    return cluster_docs, cluster_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Initialize Cluster Documents\n",
    "Runs the function above to create text descriptions for each property cluster. These descriptions will be used for semantic search and analysis later.\n",
    "\n",
    "Each document contains key statistics about the properties in that cluster, including average prices, satisfaction scores, distances, and distributions of room types and cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cluster documents and initialize the vectorizer\n",
    "cluster_docs, cluster_ids = create_cluster_documents(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Search Through Clusters\n",
    "Uses text analysis with TF-IDF vectorization and cosine similarity to find clusters that best match what users are looking for in their ideal property.\n",
    "\n",
    "The search compares the user's query against the detailed cluster descriptions we created above, finding the most semantically similar matches. This helps users discover property groups that align with their preferences, even if they don't use exact matching terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer for text search\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "document_vectors = vectorizer.fit_transform(cluster_docs)\n",
    "\n",
    "def retrieve_relevant_docs(query, top_k=3):\n",
    "    \"\"\"Find the clusters that best match a search query.\"\"\"\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, document_vectors).flatten()\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    # Return both the documents and their cluster IDs\n",
    "    return [cluster_docs[i] for i in top_indices], [cluster_ids[i] for i in top_indices], similarities[top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Name the Clusters\n",
    "Uses the Llama 3 model to generate intuitive, descriptive names for each cluster based on their distinctive characteristics. \n",
    "\n",
    "The naming process analyzes multiple feature groups (Distance, Accommodation, Quality, Price, and Superhost status) to identify what makes each cluster unique. The model then creates memorable names that highlight these key traits, making it easier for users to understand the different types of properties available.\n",
    "\n",
    "For example, a cluster might be named \"Urban Luxury Oasis\" if it contains high-end properties close to city centers with excellent ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to name clusters based on key traits\n",
    "def name_clusters(df):\n",
    "    \"\"\"Give each cluster a descriptive name based on its main features.\"\"\"\n",
    "    # Get cluster documents\n",
    "    cluster_docs, cluster_ids = create_cluster_documents(df)\n",
    "    # Define feature groups for cluster analysis\n",
    "    feature_groups = {\n",
    "        'Distance': ['dist', 'metro_dist'],\n",
    "        'Accommodation': ['bedrooms', 'person_capacity'], \n",
    "        'Quality': ['cleanliness_rating', 'guest_satisfaction_overall'],\n",
    "        'Price': ['realSum'],\n",
    "        'Superhost': ['host_is_superhost_bool']\n",
    "    }\n",
    "    \n",
    "    # Create descriptive names for each cluster\n",
    "    client = Llama3Client()\n",
    "    \n",
    "    for cluster_id in cluster_ids:\n",
    "        cluster_data = df[df['cluster'] == cluster_id]\n",
    "        \n",
    "        # Calculate feature group averages\n",
    "        group_stats = {}\n",
    "        for group_name, features in feature_groups.items():\n",
    "            # Calculate mean of standardized values for features in group\n",
    "            feature_means = []\n",
    "            for feature in features:\n",
    "                if feature in cluster_data.columns:\n",
    "                    mean = cluster_data[feature].mean()\n",
    "                    std = df[feature].std()  # Using full dataset std\n",
    "                    feature_means.append((mean - df[feature].mean()) / std)\n",
    "            if feature_means:\n",
    "                group_stats[group_name] = np.mean(feature_means)\n",
    "        \n",
    "        # Sort groups by absolute z-score to find most distinctive traits\n",
    "        distinctive_groups = sorted(group_stats.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "        top_groups = [g[0] for g in distinctive_groups[:3]]\n",
    "        \n",
    "        # Get the cluster document\n",
    "        doc = cluster_docs[cluster_ids.index(cluster_id)]\n",
    "        \n",
    "        prompt = f\"\"\"[Task]\n",
    "        Create a concise, memorable name for an Airbnb property cluster that captures its key characteristics, unique to the specific cluster.\n",
    "        \n",
    "        [Target]\n",
    "        - Primary: Potential Airbnb guests looking for specific property types\n",
    "        - Secondary: Property managers seeking to position their listings\n",
    "        \n",
    "        [Tone]\n",
    "        Professional yet approachable, using clear and appealing language suitable for property listings\n",
    "\n",
    "        [Trait]\n",
    "        You are a branding-savvy data analyst with experience in real estate and hospitality. \n",
    "        You understand how to translate statistical insights into marketable, intuitive names that resonate with both guests and hosts.\n",
    "        \n",
    "        [Technical Details]\n",
    "        1. Output Format: Return ONLY a cluster name following this exact pattern:\n",
    "           \"Descriptive Name ({', '.join(top_groups)})\"\n",
    "           Example: \"Urban Luxury Oasis (Distance: 2.1 km to center, Quality: 4.8 rating, Price: $250 per night)\"\n",
    "        \n",
    "        2. Key Data Points:\n",
    "           - Distinctive feature groups: {', '.join(top_groups)}\n",
    "           - Cluster characteristics:\n",
    "             {doc}\n",
    "        \n",
    "        3. Requirements:\n",
    "           - Name must be immediately understandable\n",
    "           - Include specific metrics for each feature group\n",
    "           - Accurately reflect the data-driven grouping\n",
    "        \"\"\"\n",
    "        \n",
    "        cluster_name = client.ask(prompt)\n",
    "        display(Markdown(f\"**Cluster {cluster_id}:** {cluster_name}\"))\n",
    "\n",
    "# Generate cluster names\n",
    "name_clusters(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
