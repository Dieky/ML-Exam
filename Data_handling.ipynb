{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8e7a27-c2af-4ea3-b2c2-05712b27caf5",
   "metadata": {},
   "source": [
    "## **Introduction & Explanation: Airbnb Data Preparation Scripts**\n",
    "\n",
    "This notebook contains two important preprocessing scripts that prepare Airbnb price and listing data for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3aae2-db19-4eb9-808a-19237785c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# https://www.kaggle.com/datasets/thedevastator/airbnb-prices-in-european-cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b511a-f416-4e5f-878e-6fa1895a72fe",
   "metadata": {},
   "source": [
    "#### **Unsupervised Learning Dataset Creation**\n",
    "\n",
    "This section builds the dataset used for unsupervised learning tasks such as clustering.\n",
    "\n",
    "1. **Combining Data**\n",
    "\n",
    "   * Loads multiple CSV files (weekends, weekdays) from the Airbnb European cities folder.\n",
    "   * Adds a `City` column (cleaned name) and an `Is_weekend` flag for each entry.\n",
    "   * Combines everything into a single DataFrame.\n",
    "\n",
    "2. **Cleaning the Data**\n",
    "\n",
    "   * Drops unnecessary columns like coordinates and index scores.\n",
    "   * Renames `'Unnamed: 0'` to `'ID'` if present.\n",
    "   * Converts boolean fields to integer flags (adds `_bool` suffix).\n",
    "\n",
    "3. **Outlier Removal**\n",
    "\n",
    "   * Removes extreme price outliers (top 1%) to keep the dataset focused on typical listings.\n",
    "\n",
    "4. **Final Touch**\n",
    "\n",
    "   * Rounds distance, price, and related numeric fields for consistency.\n",
    "   * Saves the cleaned dataset as `cleaned_airbnb_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dad515-927d-413c-a628-c2d78facaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO CREATE THE FINAL DATASET FOR UNSUPERVISED LEARNING MODEL\n",
    "# Step 1: Combine all CSV files\n",
    "folder_path = './data/airbnb-prices-in-european-cities/'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "combined_df = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    filename_no_ext = os.path.splitext(file)[0]\n",
    "    if filename_no_ext.endswith('_weekends'):\n",
    "        city = filename_no_ext.replace('_weekends', '').capitalize()\n",
    "        is_weekend = True\n",
    "    elif filename_no_ext.endswith('_weekdays'):\n",
    "        city = filename_no_ext.replace('_weekdays', '').capitalize()\n",
    "        is_weekend = False\n",
    "    else:\n",
    "        city = filename_no_ext.capitalize()\n",
    "        is_weekend = pd.NA\n",
    "\n",
    "    df['City'] = city\n",
    "    df['Is_weekend'] = is_weekend\n",
    "    combined_df.append(df)\n",
    "\n",
    "final_df = pd.concat(combined_df, ignore_index=True)\n",
    "\n",
    "# Step 2: Clean and optimize\n",
    "def clean_airbnb_data(df):\n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = ['lng', 'lat', 'attr_index', 'attr_index_norm', 'rest_index', 'rest_index_norm']\n",
    "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "\n",
    "    # Rename 'Unnamed: 0' to 'ID' if present\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.rename(columns={'Unnamed: 0': 'ID'})\n",
    "\n",
    "    # Convert boolean columns to 0/1 and add \"_bool\" suffix\n",
    "    bool_cols = df.select_dtypes(include='bool').columns.tolist()\n",
    "\n",
    "    # Add explicitly boolean-like int columns\n",
    "    manual_bool_cols = ['biz', 'multi']\n",
    "    \n",
    "    for col in bool_cols + manual_bool_cols:\n",
    "        df[col] = df[col].astype(int)\n",
    "        df.rename(columns={col: f\"{col}_bool\"}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 3: Remove outliers\n",
    "def remove_price_outliers(df, column='realSum', quantile=0.99):\n",
    "    threshold = df[column].quantile(quantile)\n",
    "    return df[df[column] < threshold].copy()\n",
    "\n",
    "# Apply cleaning and filtering\n",
    "cleaned_df = clean_airbnb_data(final_df)\n",
    "cleaned_df = remove_price_outliers(cleaned_df)\n",
    "\n",
    "# Round selected values\n",
    "cleaned_df['dist'] = cleaned_df['dist'].round(1)\n",
    "cleaned_df['metro_dist'] = cleaned_df['metro_dist'].round(1)\n",
    "cleaned_df['realSum'] = cleaned_df['realSum'].round(2)\n",
    "cleaned_df['person_capacity'] = cleaned_df['person_capacity'].round(0).astype(int)\n",
    "cleaned_df['cleanliness_rating'] = cleaned_df['cleanliness_rating'].round(0).astype(int)\n",
    "cleaned_df['guest_satisfaction_overall'] = cleaned_df['guest_satisfaction_overall'].round(0).astype(int)\n",
    "\n",
    "# Step 4: Save to a new CSV\n",
    "output_path = os.path.join('./data/', 'cleaned_airbnb_data.csv')\n",
    "cleaned_df.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01d9c3-2a31-4ec3-92b5-8c80cc63c879",
   "metadata": {},
   "source": [
    "#### **Supervised Learning Dataset Creation**\n",
    "\n",
    "This section prepares a cleaned dataset tailored for supervised learning models such as regression or classification.\n",
    "\n",
    "1. **Combining Data**\n",
    "\n",
    "   * Same as in the unsupervised pipeline: combines all CSV files and adds city and weekend flags.\n",
    "\n",
    "2. **Cleaning and Encoding**\n",
    "\n",
    "   * Drops unnecessary columns and renames `'Unnamed: 0'` to `'ID'`.\n",
    "   * Converts boolean fields to integer flags (adds `_bool` suffix).\n",
    "   * Encodes categorical columns like `'City'` and `'room_type'` into numeric IDs starting from 1, making them suitable for machine learning models.\n",
    "\n",
    "3. **Final Touch**\n",
    "\n",
    "   * Rounds distances, prices, and rating fields.\n",
    "   * Saves the cleaned dataset as `supervised_cleaned_airbnb_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e380e-6f7f-4efb-82c0-5bf347eb14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO CREATE THE FINAL DATASET FOR SUPERVISED LEARNING MODEL\n",
    "# Step 1: Combine all CSV files\n",
    "folder_path = './data/airbnb-prices-in-european-cities/'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "combined_df = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    filename_no_ext = os.path.splitext(file)[0]\n",
    "    if filename_no_ext.endswith('_weekends'):\n",
    "        city = filename_no_ext.replace('_weekends', '').capitalize()\n",
    "        is_weekend = True\n",
    "    elif filename_no_ext.endswith('_weekdays'):\n",
    "        city = filename_no_ext.replace('_weekdays', '').capitalize()\n",
    "        is_weekend = False\n",
    "    else:\n",
    "        city = filename_no_ext.capitalize()\n",
    "        is_weekend = pd.NA\n",
    "\n",
    "    df['City'] = city\n",
    "    df['Is_weekend'] = is_weekend\n",
    "    combined_df.append(df)\n",
    "\n",
    "final_df = pd.concat(combined_df, ignore_index=True)\n",
    "\n",
    "# Step 2: Clean and optimize\n",
    "def clean_airbnb_data(df):\n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = ['lng', 'lat', 'attr_index', 'attr_index_norm', 'rest_index', 'rest_index_norm']\n",
    "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "\n",
    "    # Rename 'Unnamed: 0' to 'ID' if present\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.rename(columns={'Unnamed: 0': 'ID'})\n",
    "\n",
    "    # Convert boolean columns to 0/1 and add \"_bool\" suffix\n",
    "    bool_cols = df.select_dtypes(include='bool').columns.tolist()\n",
    "\n",
    "    # Add explicitly boolean-like int columns\n",
    "    manual_bool_cols = ['biz', 'multi']\n",
    "    \n",
    "    for col in bool_cols + manual_bool_cols:\n",
    "        df[col] = df[col].astype(int)\n",
    "        df.rename(columns={col: f\"{col}_bool\"}, inplace=True)\n",
    "\n",
    "    # Convert 'City' to numeric ID starting from 1\n",
    "    unique_cities = df['City'].unique()\n",
    "    city_mapping = {city: idx + 1 for idx, city in enumerate(unique_cities)}\n",
    "    df['City'] = df['City'].map(city_mapping)\n",
    "\n",
    "    # Convert 'Room_type' to numeric ID starting from 1\n",
    "    room_types = df['room_type'].unique()\n",
    "    room_type_mapping = {room_type: idx + 1 for idx, room_type in enumerate(room_types)}\n",
    "    df['room_type'] = df['room_type'].map(room_type_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "cleaned_df = clean_airbnb_data(final_df)\n",
    "\n",
    "cleaned_df['dist'] = cleaned_df['dist'].round(1)\n",
    "cleaned_df['metro_dist'] = cleaned_df['metro_dist'].round(1)\n",
    "cleaned_df['realSum'] = cleaned_df['realSum'].round(2)\n",
    "cleaned_df['person_capacity'] = cleaned_df['person_capacity'].round(0).astype(int)\n",
    "cleaned_df['cleanliness_rating'] = cleaned_df['cleanliness_rating'].round(0).astype(int)\n",
    "cleaned_df['guest_satisfaction_overall'] = cleaned_df['guest_satisfaction_overall'].round(0).astype(int)\n",
    "\n",
    "# Step 3: Save to a new CSV\n",
    "output_path = os.path.join('./data/', 'supervised_cleaned_airbnb_data.csv')\n",
    "cleaned_df.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e042ef-15ca-4309-a601-e42c7795e524",
   "metadata": {},
   "source": [
    "### **Summary**\n",
    "These two scripts transform raw, multi-source Airbnb data into machine learning-ready datasets: one optimized for pattern discovery (unsupervised) and the other for predictive modeling (supervised), ensuring clean, encoded, and consistently formatted input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce76bed-52ba-46b3-9dad-4767912823c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
